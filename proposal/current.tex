\section*{Current Work}
We have implemented liquidHaskell, a tool that given Haskell source code 
and some specifications 
verifies that the code
satisfies the specifications.\\

\textbf{Specifications}
are expressed as \textit{refinement types}, ie., types annotated with logical predicates.
As an example, the type $\left\lbrace v : \text{Int}\ |\ v > 0 \right\rbrace $ 
describes a value $v$ which is an integer 
and the refinements specifies that this value is greater than zero.
%
The language of the predicates contains logical formulas, linear arithmetic and uninterpreted functions. 
%
Using uninterpreted functions the user can define \textit{measures} on Haskell data types, 
for instance, she can define a measure \textit{len} that captures the length of a list 
and use it to specify interesting list properties.

There are two major advantages on this formulation.
%
Firstly, specification language is simple
as most programmers are familiar with both
its ingredients, ie., Haskell types and logical formulas.
%
Secondly, verification is equivalent to refinement type checking,
which in turn, through constraint generation, goes down to 
decidable implication checking
that can be verified by an STM solver.
\\

\textbf{The tool:}
LiquidHaskell, takes as input
a target Haskell source file, with the desired refinement types specified as a special
form of comment annotation.
%
After analysing the program, liquidHaskell returns as output:

\begin{itemize}
\item
Either SAFE, indicating that all the specifications indeed verify, 
or UNSAFE, indicating there are refinement type errors, together with the positions in the source
code where type checking fails.
\item
An HTML file containing the program source code annotated with inferred refinement types for all sub-expressions in the program. 
When a type error is reported,  it is highlighted with red color, and the programmer can use the inferred
types to determine why their program does not typecheck: they can examine what
properties liquidHaskell can deduce about various program expressions and 
provide stronger specification or alter the program as necessary so that it typechecks.
\end{itemize}


\textbf{Benchmarks:}
We used liquidHaskell to verify safety and functional correctness properties of the following Haskell libraries:

\begin{itemize}
\item \texttt{GHC.List}, which implements many standard Prelude list
operations; we verify various size related properties,
\item \texttt{Data.Set.Splay}, which implements a set data type; 
we verify that all interface functions return well ordered trees,
\item \texttt{Data.Map.Base}, which implements a functional map data
type; we verify that all interface functions return
binary-search trees,
\item \texttt{Bytestring}, a library for manipulating byte arrays, we 
verify size-based low-level memory safety and high-level 
functional correctness properties, and
\item \texttt{Text}, a library for high-performance unicode text processing; 
we verify various pointer safety and functional correctness
properties, during which we find a subtle bug.
\end{itemize}

As a quantitative summary, 
these libraries sum up to 8706 lines of code and require 
1750 lines of annotations.
Moreover, verification time scales
with respect to both the number of lines 
and the complexity of the specifications
averaging about 1 sec per 8 lines of code.

%
%\textbf{NEW}
%%% what is new
%When implementing liquid types for haskell we had to consider haskell-specific features that lead to unsoundeness,
%specifically type class constraints and laziness.
%
%% Type class constraints 
%To keep both precision and soundness in the presence of type class constraints, 
%we came up with Abstract Refinement Types that allows a type to be parameterized over its refinements.
%As an example, we refine the type of a max function as
%
%max :: forall a <p :: a -> Prop>. Ord a => {v:a | p v} -> {v:a | p v} -> {v:a | p v}
%max x y = if x >= y then x else y
%
%expressing that for any predicate p on values of type a 
%if both inputs satisfy p then the output will satisfy p
%
%It turns out that abstract refinement types greatly enhance the expressiveness of the system
%without increasing its complexity.
%We treat abstract refinements as uninterpreted function symbols, which are already supported 
%by the logic. On the same time, they can be used to propagate properties of input to the output (as in the case of max),
%to express recursive or index dependent invariants of data-types and to refine higher order functions.
%
%% Laziness
%In the presence of laziness traditional refinement systems become unsound.
%This is because of the different (with respect to strict) treatment of infinite computations:
%
%let x = non-terminating
%in     ... assert (false) ...
%
%In a strict language, computation will get stuck while evaluating x, 
%after which every assertion, even the contradiction false, can be verified.
%
%In a lazy setting, a thunk will be created for x and computation will proceed, 
%thus the above assertion should be marked as unsafe.
%
%Verification of the strict alternative is achieved because the refinement type of the
%no-terminating computation carries some information that allows the system to prove any 
%forthcoming assertion.
%
%To address the unsoundness in the lazy setting we choose to ignore the information carried 
%by any potentially non-terminating computation.
%
%To do so, we need a mechanism to identify all such computations.
%It is straightforward to extend refinement types to support a size based termination analysis.
%
%This approach has both advantages and disadvantages.
%One one hand, we ignore all information carried by non-terminating computations.
%even the meaningful ones.
%
%On the other, we regain soundness under lazy evaluation, and 
%liquidHaskell can be used for termination analysis.
%
%
